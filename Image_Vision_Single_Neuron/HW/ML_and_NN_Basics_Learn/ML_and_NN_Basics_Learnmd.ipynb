{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning (ML) and Neural Networks (NN) basics \n",
    "### Questions\n",
    "\n",
    "1. What training methods exist in ML (Learning modes)?\n",
    "2. What is a neural network (NN)?\n",
    "3. What does weight mean?\n",
    "4. What does \"neural layer\" mean?\n",
    "5. What is an \"epoch\" (epoch)?\n",
    "6. What is the \"activation function\"?\n",
    "7. How can the accuracy of the trained model be increased?\n",
    "8. What would it change if the number of neurons were increased hundreds of times, as well as the number of layers with neurons?\n",
    "9. What is the name of the training / model when a multi-layer network is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "<hr>\n",
    "\n",
    "##  1. Training methods  in ML <br>\n",
    " <img src=\"Training methods in ML.png\" style=\"width:400px;height 400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is a neural network (NN)?\n",
    "\n",
    "Artificial neural networks (ANNs), usually simply called neural networks (NNs) or, more simply yet, neural nets, are computing systems inspired by the biological neural networks that constitute animal brains.\n",
    "\n",
    "An artificial neural network is an interconnected group of nodes, inspired by a simplification of neurons in a brain. Here, each circular node represents an artificial neuron and an arrow represents a connection from the output of one artificial neuron to the input of another.\n",
    "An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron receives signals then processes them and can signal neurons connected to it. The \"signal\" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. The connections are called edges. Neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Neurons may have a threshold such that a signal is sent only if the aggregate signal crosses that threshold. Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times.\n",
    " <img src=\"111.png\" style=\"width:200px;height 200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What does weight mean?\n",
    "What is Weight (Artificial Neural Network)? Weight is the parameter within a neural network that transforms input data within the network's hidden layers. A neural network is a series of nodes, or neurons. Within each node is a set of inputs, weight, and a bias value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What does \"neural layer\" mean?\n",
    "\n",
    "A neural network can contains any number of neurons. These neurons are organized in the form of interconnected layers. The input layer can be used to represent the dataset and the initial conditions on the data.\n",
    "\n",
    "For example, suppose the input is a grayscale image, the output of every neuron in the input layer would be the intensity of every pixel of the image.\n",
    "\n",
    "This is the reason we don’t count the input layer as a part of the other layers in the neural network. When we refer to a 1-layer net, we actually refer to a simple network that contains one single layer, the output, and the additional input layer.\n",
    "\n",
    "We have previously seen that output layer can have one neuron. But there are cases where the output layer can have more than one neuron as well.\n",
    "\n",
    "The case of output layer having more than one neuron is useful in classification, because each output neuron would represent one class.\n",
    "\n",
    "Consider the example of the Modified National Institute of Standards and Technology (MNIST) dataset.\n",
    "\n",
    "We can output multiple (10 in this case) neurons, where every neuron corresponds to one digit that belongs to any number between 0 and 0.\n",
    "\n",
    "This way, the 1-layer neural network can also be used to classify the digit on each image.\n",
    "\n",
    "This can be done by taking the output neuron that has the highest activation function value. If the highest activation function value is on y5 , we can understand that the network interprets the image shown as number 5.\n",
    "\n",
    "The neurons of one-layer in the neural network can be connected to the neurons of other layers, but they can’t be connected to other neurons of the same layer.\n",
    "\n",
    "*  What is the need to organize the neurons in layers in the first place?\n",
    "One reason is that the neuron conveys limited information (just a single value). But when the neurons in the layers are combined, their outputs produce a vector. Instead of single activation, the entire vector can now be considered. This way, a lot more information can be conveyed. This is because the vector contains multiple values, and the relative ratio between the values in the vector carry metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What is an \"epoch\" (epoch)?\n",
    "An epoch in machine learning means one complete pass of the training dataset through the algorithm. This epochs number is an important hyperparameter for the algorithm. It specifies the number of epochs or complete passes of the entire training dataset passing through the training or learning process of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Activation Functions\n",
    "An activation function in a neural network defines how the weighted sum of the input is transformed into an output from a node or nodes in a layer of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. How can the accuracy of the trained model be increased?\n",
    "#### 8 Methods to Boost the Accuracy of a Model\n",
    "The model development cycle goes through various stages, starting from data collection to model building.\n",
    "\n",
    "But, before exploring the data to understand relationships (in variables), It’s always recommended to perform hypothesis generation. (To know more  about hypothesis generation, refer to this link). I believe this is the most under – rated step of predictive modeling.\n",
    "\n",
    "It is important that you spend time thinking on the given problem and gaining the domain knowledge. So, how does it help?\n",
    "\n",
    "This practice usually helps in building better features later on, which are not biased by the data available in the data-set. This is a crucial step which usually improves a model’s accuracy.\n",
    "\n",
    "At this stage, you are expected to apply structured thinking to the problem i.e. a thinking process which takes into consideration all the possible aspects of a particular problem.\n",
    "\n",
    "Let’s dig deeper now. Now we’ll check out the proven way to improve the accuracy of a model:\n",
    "##### 1. Add more data\n",
    "Having more data is always a good idea. It allows the “data to tell for itself,” instead of relying on assumptions and weak correlations. Presence of more data results in better and accurate models.\n",
    "\n",
    "I understand, we don’t get an option to add more data. For example: we do not get a choice to increase the size of training data in data science competitions. But while working on a company project, I suggest you to ask for more data, if possible. This will reduce your pain of working on limited data sets.\n",
    "##### 2. Treat missing and Outlier values\n",
    "The unwanted presence of missing and outlier values in the training data often reduces the accuracy of a model or leads to a biased model. It leads to inaccurate predictions. This is because we don’t analyse the behavior and relationship with other variables correctly. So, it is important to treat missing and outlier values well.\n",
    "\n",
    "Look at the below snapshot carefully. It shows that, in presence of missing values, the chances of playing cricket by females is similar as males. But, if you look at the second table (after treatment of missing values based on salutation of name, “Miss” ), we can see that females have higher chances of playing cricket compared to males.\n",
    "<br>\n",
    " <img src=\"Data_Exploration_2_11.png\" style=\"width:300px;height 300px\"/>\n",
    "<br>\n",
    "Above, we saw the adverse effect of missing values on the accuracy of a model. Gladly, we have various methods to deal with missing and outlier values:\n",
    "\n",
    "* Missing: In case of continuous variables, you can impute the missing values with mean, median, mode. For categorical variables, you can treat variables as a separate class. You can also build a model to predict the missing values. KNN imputation offers a great option to deal with missing values. To know more about these methods refer article “Methods to deal and treat missing values“.\n",
    "* Outlier: You can delete the observations, perform transformation, binning, Imputation (Same as missing values) or you can also treat outlier values separately.  You can refer article “How to detect Outliers in your dataset and treat them?” to know more about these methods.\n",
    "<br>\n",
    "\n",
    "##### 3. Feature Engineering\n",
    "This step helps to extract more information from existing data. New information is extracted in terms of new features. These features may have a higher ability to explain the variance in the training data. Thus, giving improved model accuracy.\n",
    "\n",
    "Feature engineering is highly influenced by hypotheses generation. Good hypothesis result in good features. That’s why, I always suggest to invest quality time in hypothesis generation. Feature engineering process can be divided into two steps:\n",
    "\n",
    "* Feature transformation: There are various scenarios where feature transformation is required:\n",
    "A) Changing the scale of a variable from original scale to scale between zero and one. This is known as data normalization. For example: If a data set has 1st variable in meter, 2nd in centi-meter and 3rd in kilo-meter, in such case, before applying any algorithm, we must normalize these variable in same scale.\n",
    "B) Some algorithms works well with normally distributed data. Therefore, we must remove skewness of variable(s). There are methods like log, square root or inverse of the values to remove skewness.\n",
    "<br>\n",
    "<img src=\"Transformation_1.png\" style=\"width:500px;height 500px\"/>\n",
    "<br>\n",
    "C) Some times, creating bins of numeric data works well, since it handles the outlier values also. Numeric data can be made discrete by grouping values into bins. This is known as data discretization.\n",
    " \n",
    "* Feature Creation: Deriving new variable(s ) from existing variables is known as feature creation. It helps to unleash the hidden relationship of a data set. Let’s say, we want to predict the number of transactions in a store based on transaction dates. Here transaction dates may not have direct correlation with number of transaction, but if we look at the day of a week, it may have a higher correlation. In this case, the information about day of a week is hidden. We need to extract it to make the model better.\n",
    "#####  4. Feature Selection\n",
    "Feature Selection is a process of finding out the best subset of attributes which better explains the relationship of independent variables with target variable.\n",
    "<br>\n",
    "<img src=\"selection.png\" style=\"width:200px;height 200px\"/>\n",
    "<br>\n",
    "You can select the useful features based on various metrics like:\n",
    "\n",
    "* Domain Knowledge: Based on domain experience, we select feature(s) which may have higher impact on target variable.\n",
    "* Visualization: As the name suggests, it helps to visualize the relationship between variables, which makes your variable selection process easier.\n",
    "<br>\n",
    "<img src=\"box-plot.png\" style=\"width:200px;height 200px\"/>\n",
    "<br>\n",
    "\n",
    "* Statistical Parameters: We also consider the p-values, information values and other statistical metrics to select right features.\n",
    "    * PCA: It helps to represent training data into lower dimensional spaces, but still characterize the inherent relationships in the data. It is a type of dimensionality reduction technique. There are various methods to reduce the dimensions (features) of training data like factor analysis, low variance, higher correlation, backward/ forward feature selection and others.\n",
    "\n",
    "##### 5. Multiple algorithms\n",
    "Hitting at the right machine learning algorithm is the ideal approach to achieve higher accuracy. But, it is easier said than done.\n",
    "\n",
    "This intuition comes with experience and incessant practice. Some algorithms are better suited to a particular type of data sets than others. Hence, we should apply all relevant models and check the performance.\n",
    "<br>\n",
    "<img src=\"ml_map-1024x638.png\" style=\"width:500px;height 500px\"/>\n",
    "<br>\n",
    "\n",
    "##### 6. Algorithm Tuning\n",
    "We know that machine learning algorithms are driven by parameters. These parameters majorly influence the outcome of learning process.\n",
    "\n",
    "The objective of parameter tuning is to find the optimum value for each parameter to improve the accuracy of the model. To tune these parameters, you must have a good understanding of these meaning and their individual impact on model. You can repeat this process with a number of well performing models.\n",
    "\n",
    "For example: In random forest, we have various parameters like max_features, number_trees, random_state, oob_score and others. Intuitive optimization of these parameter values will result in better and more accurate models.\n",
    "\n",
    "You can refer article “Tuning the parameters of your Random Forest model” to learn the impact of parameter tuning in detail. Below is random forest scikit learn algorithm with list of all parameters:-\n",
    "\n",
    "<tt class=\"descname\">RandomForestClassifier</tt>(<em>n_estimators=10</em>, <em>criterion='gini'</em>, <em>max_depth=None</em>,<em>min_samples_split=2</em>, <em>min_samples_leaf=1</em>, <em>min_weight_fraction_leaf=0.0</em>, <em>max_features='auto'</em>, <em>max_leaf_nodes=None</em>,<em>bootstrap=True</em>, <em>oob_score=False</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>verbose=0</em>, <em>warm_start=False</em>,<em>class_weight=None</em>)<br>\n",
    "<img src=\"knobs.png\" style=\"width:500px;height 500px\"/> <br>\n",
    "\n",
    "##### 7. Ensemble methods\n",
    "This is the most common approach found majorly in winning solutions of Data science competitions. This technique simply combines the result of multiple weak models and produce better results. This can be achieved through many ways:\n",
    "\n",
    "* Bagging (Bootstrap Aggregating)\n",
    "* Boosting\n",
    "\n",
    "<br>\n",
    "To know more about these methods, you can refer article “Introduction to ensemble learning“.\n",
    "\n",
    "It is always a better idea to apply ensemble methods to improve the accuracy of your model. There are two good reasons for this: a ) They are generally more complex than traditional methods. b) The traditional methods give you a good base level from which you can improve and draw from to create your ensembles.\n",
    " \n",
    "##### Caution!\n",
    "Till here, we have seen methods which can improve the accuracy of a model. But, it is not necessary that higher accuracy models always perform better (for unseen data points). Sometimes, the improvement in model’s accuracy can be due to over-fitting too.\n",
    "\n",
    "##### 8. Cross Validation:\n",
    " To find the right answer of this question, we must use cross validation technique. Cross Validation is one of the most important concepts in data modeling. It says, try to leave a sample on which you do not train the model and test the model on this sample before finalizing the model.<br>\n",
    " <img src=\"validation.png\" style=\"width:400px;height 400px\"/> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### 8.What would it change if the number of neurons were increased hundreds of times, as well as the number of layers with neurons?\n",
    "* The increase of neurons in an ANN leads to the increase of accuracy and the possibility of increasing the complexity of the ANN\n",
    "\n",
    "##### 9. What is the name of the training / model when a multi-layer network is used?\n",
    "<h4>Stochastic Gradient Descent</h4>\n",
    "The classical and still preferred training algorithm for neural networks is called stochastic gradient descent.\n",
    "\n",
    "This is where one row of data is exposed to the network at a time as input. The network processes the input upward, activating neurons as it goes to finally produce an output value. This is called a forward pass on the network. It is the type of pass that is also used after the network is trained in order to make predictions on new data.\n",
    "\n",
    "The output of the network is compared to the expected output, and an error is calculated. This error is then propagated back through the network, one layer at a time, and the weights are updated according to the amount they contributed to the error. This clever bit of math is called the backpropagation algorithm.\n",
    "\n",
    "The process is repeated for all of the examples in your training data. One round of updating the network for the entire training dataset is called an epoch. A network may be trained for tens, hundreds, or many thousands of epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
