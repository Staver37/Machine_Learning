{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML/ Image Quality Detector\n",
    "> part 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "\n",
    "1. optimize the learning \n",
    "2. expand the dataset up till 1000 images\n",
    "3. increase the  filters up to 64\n",
    "4. increase the number of training epochh 5000-10000\n",
    "5. optimize on GPU\n",
    "https://pytorch.org/get-started/locally/\n",
    "    for  CUDA or ROCm\n",
    "    -  install the drivre CUDA\n",
    "    -  install the torch with CUDA suport\n",
    "    -  check & link to device\n",
    "    - !!! transfer all tensors & network to device\n",
    "6. optimize the stop conditions based on accuracy\n",
    "7. resource consumption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW\n",
    "1. expand the dataset up till 2000 images\n",
    "2. increase the  filters up to 96 &  kernel size / stride = 10x10\n",
    "3. increase the number of training epochh 5000-10000 |acc > 99.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image,ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "\n",
    "\n",
    "# Transfer on GPU with CUDA \n",
    "# print(\"GPU avaible ?\",torch.cuda.is_available())\n",
    "# print(\"Device\",torch.cuda.current_device())\n",
    "                            # V---- device NR\n",
    "# device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Helpers \n",
    "def loadImages(folder,start_number= 0,end_number= 2000):\n",
    "    images = []\n",
    "    count = 0\n",
    "    file_names = os.listdir(folder)\n",
    "    for number in range(start_number,end_number):\n",
    "            file_name= f\"image_{number:05d}.jpg\"\n",
    "            img = Image.open(folder+\"/\"+file_name)\n",
    "            img = ImageOps.grayscale(img)\n",
    "            img_matrix= np.array(img)\n",
    "            images.append(img_matrix)\n",
    "            # print(file_name)\n",
    "            count += 1\n",
    "            if count == number:\n",
    "                  break\n",
    "\n",
    "            \n",
    "    return images\n",
    "\n",
    "def imageToTensor(img):\n",
    "      img_tensor = torch.from_numpy(img).type(torch.FloatTensor).view(1,500,500)\n",
    "      return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training helpers\n",
    "## Let's test it\n",
    "def estimateAccuracy(model,x,y):\n",
    "    correct = 0 \n",
    "    for i in range(len(x)):\n",
    "        x_tensor= imageToTensor(x[i])     #.to(device)        # for CUDA device transfer\n",
    "        y_predicted = model(x_tensor)\n",
    "        y_tensor = torch.FloatTensor(y[i])#.to(device)        # for CUDA device transfer\n",
    "        if(torch.argmax(y_predicted)) == torch.argmax(y_tensor):\n",
    "            correct += 1\n",
    "\n",
    "            \n",
    "    accuracy = (correct / len(x))* 100       \n",
    "    print(f\"predicted correctly {accuracy}%\")\n",
    "    return accuracy\n",
    "\n",
    "def oneEpochTrain(model,x,y,criterion,optimizer):\n",
    "    for i in range(len(x)):\n",
    "\n",
    "        x_tensor= imageToTensor(x[i])     #.to(device)        # for CUDA device transfer\n",
    "        y_tensor = torch.FloatTensor(y[i])#.to(device)        # for CUDA device transfer\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_predicted = model(x_tensor)\n",
    "\n",
    "        loss = criterion(y_predicted, y_tensor)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # if epoch % 10 == 0:\n",
    "        # print(f\"epoch = {epoch:5},loss= {loss:10.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded2000 images\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_DATA_SAMPLES =1000\n",
    "\n",
    "# PREPARING DATASET\n",
    "original_images  = loadImages(\"images/original\",start_number=0, end_number=1000)\n",
    "# blurred_images   = loadImages(\"images/blurred\")   \n",
    "lowq_images      = loadImages(\"images/lowq\",start_number=0, end_number=1000)      \n",
    "# sharpened_images = loadImages(\"images/sharpened\")\n",
    "print(f\"loaded{len(original_images)+ len(lowq_images)} images\")\n",
    "\n",
    "\n",
    "## Preparing Data sets\n",
    "x = original_images + lowq_images # 100 [50 - good, 50 - bad]\n",
    "#      V --- GOOD                    V-- BAD \n",
    "y = [[0,1] for _ in range(NUMBER_OF_DATA_SAMPLES)] + [[1,0] for _ in range(NUMBER_OF_DATA_SAMPLES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep The Model     -->  create multi layer of neurons NN\n",
    "model = nn.Sequential(\n",
    "    #                            v--nn.layers      V-- pixels taken         V -- pixels steps\n",
    "    nn.Conv2d(in_channels=1,out_channels=96,kernel_size=(10,10), stride = (10,10)), # layer 0 <- Neurons\n",
    "    nn.Flatten(start_dim=0), # <------ No neurons  / transform in flatenn function\n",
    "    nn.Linear(in_features=240000, out_features=2),                                    # layer 1 <- Neurons\n",
    ")\n",
    "# for CUDA device transfer\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    0\n",
      "predicted correctly 50.0%\n",
      "epoch:    1\n",
      "predicted correctly 50.0%\n",
      "epoch:    2\n",
      "predicted correctly 50.0%\n",
      "epoch:    3\n",
      "predicted correctly 50.0%\n",
      "epoch:    4\n",
      "predicted correctly 50.0%\n",
      "epoch:    5\n",
      "predicted correctly 50.14999999999999%\n",
      "epoch:    6\n",
      "predicted correctly 50.05%\n",
      "epoch:    7\n",
      "predicted correctly 50.0%\n",
      "epoch:    8\n",
      "predicted correctly 50.24999999999999%\n",
      "epoch:    9\n",
      "predicted correctly 50.14999999999999%\n",
      "epoch:   10\n",
      "predicted correctly 50.3%\n",
      "epoch:   11\n",
      "predicted correctly 50.1%\n",
      "epoch:   12\n",
      "predicted correctly 50.14999999999999%\n",
      "epoch:   13\n",
      "predicted correctly 50.349999999999994%\n",
      "epoch:   14\n",
      "predicted correctly 50.349999999999994%\n",
      "epoch:   15\n",
      "predicted correctly 50.14999999999999%\n",
      "epoch:   16\n",
      "predicted correctly 50.6%\n",
      "epoch:   17\n",
      "predicted correctly 50.4%\n",
      "epoch:   18\n",
      "predicted correctly 50.24999999999999%\n",
      "epoch:   19\n",
      "predicted correctly 50.24999999999999%\n",
      "epoch:   20\n",
      "predicted correctly 50.24999999999999%\n",
      "epoch:   21\n",
      "predicted correctly 50.24999999999999%\n",
      "epoch:   22\n",
      "predicted correctly 50.3%\n",
      "epoch:   23\n",
      "predicted correctly 50.6%\n",
      "epoch:   24\n",
      "predicted correctly 50.3%\n",
      "epoch:   25\n",
      "predicted correctly 51.24999999999999%\n",
      "epoch:   26\n",
      "predicted correctly 50.6%\n",
      "epoch:   27\n",
      "predicted correctly 51.0%\n",
      "epoch:   28\n",
      "predicted correctly 50.55%\n",
      "epoch:   29\n",
      "predicted correctly 51.2%\n",
      "epoch:   30\n",
      "predicted correctly 50.349999999999994%\n",
      "epoch:   31\n",
      "predicted correctly 50.14999999999999%\n",
      "epoch:   32\n",
      "predicted correctly 51.6%\n",
      "epoch:   33\n",
      "predicted correctly 51.300000000000004%\n",
      "epoch:   34\n",
      "predicted correctly 50.449999999999996%\n",
      "epoch:   35\n",
      "predicted correctly 50.349999999999994%\n",
      "epoch:   36\n",
      "predicted correctly 51.2%\n",
      "epoch:   37\n",
      "predicted correctly 51.24999999999999%\n",
      "epoch:   38\n",
      "predicted correctly 51.24999999999999%\n",
      "epoch:   39\n",
      "predicted correctly 51.4%\n",
      "epoch:   40\n",
      "predicted correctly 51.7%\n",
      "epoch:   41\n",
      "predicted correctly 50.55%\n",
      "epoch:   42\n",
      "predicted correctly 51.4%\n",
      "epoch:   43\n",
      "predicted correctly 51.6%\n",
      "epoch:   44\n",
      "predicted correctly 51.65%\n",
      "epoch:   45\n",
      "predicted correctly 50.55%\n",
      "epoch:   46\n",
      "predicted correctly 50.849999999999994%\n",
      "epoch:   47\n",
      "predicted correctly 51.7%\n",
      "epoch:   48\n",
      "predicted correctly 51.74999999999999%\n",
      "epoch:   49\n",
      "predicted correctly 51.7%\n",
      "epoch:   50\n",
      "predicted correctly 50.6%\n",
      "epoch:   51\n",
      "predicted correctly 51.800000000000004%\n",
      "epoch:   52\n",
      "predicted correctly 52.05%\n",
      "epoch:   53\n",
      "predicted correctly 50.55%\n",
      "epoch:   54\n",
      "predicted correctly 50.55%\n",
      "epoch:   55\n",
      "predicted correctly 51.74999999999999%\n",
      "epoch:   56\n",
      "predicted correctly 50.8%\n",
      "epoch:   57\n",
      "predicted correctly 52.349999999999994%\n",
      "epoch:   58\n",
      "predicted correctly 50.8%\n",
      "epoch:   59\n",
      "predicted correctly 52.449999999999996%\n",
      "epoch:   60\n",
      "predicted correctly 51.7%\n",
      "epoch:   61\n",
      "predicted correctly 52.2%\n",
      "epoch:   62\n",
      "predicted correctly 52.400000000000006%\n",
      "epoch:   63\n",
      "predicted correctly 51.849999999999994%\n",
      "epoch:   64\n",
      "predicted correctly 52.449999999999996%\n",
      "epoch:   65\n",
      "predicted correctly 52.949999999999996%\n",
      "epoch:   66\n",
      "predicted correctly 52.449999999999996%\n",
      "epoch:   67\n",
      "predicted correctly 51.300000000000004%\n",
      "epoch:   68\n",
      "predicted correctly 51.7%\n",
      "epoch:   69\n",
      "predicted correctly 54.7%\n",
      "epoch:   70\n",
      "predicted correctly 54.800000000000004%\n",
      "epoch:   71\n",
      "predicted correctly 54.300000000000004%\n",
      "epoch:   72\n",
      "predicted correctly 54.55%\n",
      "epoch:   73\n",
      "predicted correctly 53.2%\n",
      "epoch:   74\n",
      "predicted correctly 54.2%\n",
      "epoch:   75\n",
      "predicted correctly 54.35%\n",
      "epoch:   76\n",
      "predicted correctly 52.300000000000004%\n",
      "epoch:   77\n",
      "predicted correctly 53.05%\n",
      "epoch:   78\n",
      "predicted correctly 55.1%\n",
      "epoch:   79\n",
      "predicted correctly 54.85%\n",
      "epoch:   80\n",
      "predicted correctly 51.7%\n",
      "epoch:   81\n",
      "predicted correctly 54.50000000000001%\n",
      "epoch:   82\n",
      "predicted correctly 53.6%\n",
      "epoch:   83\n",
      "predicted correctly 54.0%\n",
      "epoch:   84\n",
      "predicted correctly 55.400000000000006%\n",
      "epoch:   85\n",
      "predicted correctly 56.95%\n",
      "epoch:   86\n",
      "predicted correctly 52.400000000000006%\n",
      "epoch:   87\n",
      "predicted correctly 55.75%\n",
      "epoch:   88\n",
      "predicted correctly 56.55%\n",
      "epoch:   89\n",
      "predicted correctly 52.449999999999996%\n",
      "epoch:   90\n",
      "predicted correctly 55.35%\n",
      "epoch:   91\n",
      "predicted correctly 56.05%\n",
      "epoch:   92\n",
      "predicted correctly 53.2%\n",
      "epoch:   93\n",
      "predicted correctly 55.300000000000004%\n",
      "epoch:   94\n",
      "predicted correctly 54.449999999999996%\n",
      "epoch:   95\n",
      "predicted correctly 53.55%\n",
      "epoch:   96\n",
      "predicted correctly 57.25%\n",
      "epoch:   97\n",
      "predicted correctly 57.4%\n",
      "epoch:   98\n",
      "predicted correctly 57.599999999999994%\n",
      "epoch:   99\n",
      "predicted correctly 57.99999999999999%\n",
      "epoch:  100\n",
      "predicted correctly 57.25%\n",
      "epoch:  101\n",
      "predicted correctly 53.05%\n",
      "epoch:  102\n",
      "predicted correctly 58.25%\n",
      "epoch:  103\n",
      "predicted correctly 53.6%\n",
      "epoch:  104\n",
      "predicted correctly 59.150000000000006%\n",
      "epoch:  105\n",
      "predicted correctly 57.85%\n",
      "epoch:  106\n",
      "predicted correctly 53.0%\n",
      "epoch:  107\n",
      "predicted correctly 55.25%\n",
      "epoch:  108\n",
      "predicted correctly 57.45%\n",
      "epoch:  109\n",
      "predicted correctly 57.75%\n",
      "epoch:  110\n",
      "predicted correctly 58.650000000000006%\n",
      "epoch:  111\n",
      "predicted correctly 59.550000000000004%\n",
      "epoch:  112\n",
      "predicted correctly 59.9%\n",
      "epoch:  113\n",
      "predicted correctly 56.55%\n",
      "epoch:  114\n",
      "predicted correctly 58.099999999999994%\n",
      "epoch:  115\n",
      "predicted correctly 58.8%\n",
      "epoch:  116\n",
      "predicted correctly 57.99999999999999%\n",
      "epoch:  117\n",
      "predicted correctly 59.050000000000004%\n",
      "epoch:  118\n",
      "predicted correctly 53.849999999999994%\n",
      "epoch:  119\n",
      "predicted correctly 57.35%\n",
      "epoch:  120\n",
      "predicted correctly 58.25%\n",
      "epoch:  121\n",
      "predicted correctly 57.699999999999996%\n",
      "epoch:  122\n",
      "predicted correctly 59.699999999999996%\n",
      "epoch:  123\n",
      "predicted correctly 59.650000000000006%\n",
      "epoch:  124\n",
      "predicted correctly 52.75%\n",
      "epoch:  125\n",
      "predicted correctly 55.900000000000006%\n",
      "epoch:  126\n",
      "predicted correctly 59.199999999999996%\n",
      "epoch:  127\n",
      "predicted correctly 56.65%\n",
      "epoch:  128\n",
      "predicted correctly 56.00000000000001%\n",
      "epoch:  129\n",
      "predicted correctly 56.75%\n",
      "epoch:  130\n",
      "predicted correctly 54.900000000000006%\n",
      "epoch:  131\n",
      "predicted correctly 56.05%\n",
      "epoch:  132\n",
      "predicted correctly 58.25%\n",
      "epoch:  133\n",
      "predicted correctly 57.85%\n",
      "epoch:  134\n",
      "predicted correctly 59.199999999999996%\n",
      "epoch:  135\n",
      "predicted correctly 54.1%\n",
      "epoch:  136\n",
      "predicted correctly 57.49999999999999%\n",
      "epoch:  137\n",
      "predicted correctly 58.8%\n"
     ]
    }
   ],
   "source": [
    "## Training setup\n",
    "for epoch in range(10000):\n",
    "    oneEpochTrain(model,x,y,criterion,optimizer)\n",
    "    print(f\"epoch:{epoch:5}\")\n",
    "    accuracy = estimateAccuracy(model,x,y)    \n",
    "    if accuracy >= 99.90:\n",
    "        break\n",
    "\n",
    "print(\"TRANING FINISHED!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the trained network <--https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "torch.save(model.state_dict(),'models/image-quality-detector-96-10x10-2000-x-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the trained network <--https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "# model = TheModelClass(*args, **kwargs) # <--recreate the model object\n",
    "model.load_state_dict(torch.load('models/image-quality-detector-64-20x20-1000-x-images'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING TEST DATASET\n",
    "NUMBER_OF_DATA_SAMPLES =500\n",
    "\n",
    "original_images  = loadImages(\"images/original\", start_number = 500, end_number=1000)\n",
    "lowq_images      = loadImages(\"images/lowq\",     start_number = 500, end_number=1000)      \n",
    "# blurred_images   = loadImages(\"images/blurred\")   \n",
    "# sharpened_images = loadImages(\"images/sharpened\")\n",
    "print(f\"loaded{len(original_images)+ len(lowq_images)} images\")\n",
    "\n",
    "\n",
    "## Preparing Data sets\n",
    "x_test = original_images + lowq_images # 100 [50 - good, 50 - bad]\n",
    "#      V --- GOOD                    V-- BAD \n",
    "y_test = [[0,1] for _ in range(NUMBER_OF_DATA_SAMPLES)] + [[1,0] for _ in range(NUMBER_OF_DATA_SAMPLES)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimateAccuracy(model,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 identic 0\n",
      "1 identic 1\n",
      "2 identic 2\n",
      "3 identic 3\n",
      "4 identic 4\n",
      "5 identic 5\n",
      "5 identic 25\n",
      "6 identic 6\n",
      "7 identic 7\n",
      "8 identic 8\n",
      "9 identic 9\n",
      "10 identic 10\n",
      "11 identic 11\n",
      "11 identic 35\n",
      "12 identic 12\n",
      "13 identic 13\n",
      "14 identic 14\n",
      "15 identic 15\n",
      "16 identic 16\n",
      "17 identic 17\n",
      "18 identic 18\n",
      "19 identic 19\n",
      "20 identic 20\n",
      "21 identic 21\n",
      "22 identic 22\n",
      "23 identic 23\n",
      "24 identic 24\n",
      "25 identic 5\n",
      "25 identic 25\n",
      "26 identic 26\n",
      "27 identic 27\n",
      "28 identic 28\n",
      "29 identic 29\n",
      "30 identic 30\n",
      "31 identic 31\n",
      "32 identic 32\n",
      "33 identic 33\n",
      "34 identic 34\n",
      "35 identic 11\n",
      "35 identic 35\n",
      "36 identic 36\n",
      "37 identic 37\n",
      "38 identic 38\n",
      "39 identic 39\n",
      "40 identic 40\n",
      "41 identic 41\n",
      "42 identic 42\n",
      "43 identic 43\n",
      "44 identic 44\n",
      "45 identic 45\n",
      "46 identic 46\n",
      "47 identic 47\n",
      "48 identic 48\n",
      "49 identic 49\n",
      "50 identic 50\n",
      "51 identic 51\n",
      "52 identic 52\n",
      "53 identic 53\n",
      "54 identic 54\n",
      "55 identic 55\n",
      "56 identic 56\n",
      "57 identic 57\n",
      "58 identic 58\n",
      "59 identic 59\n",
      "60 identic 60\n",
      "61 identic 61\n",
      "62 identic 62\n",
      "63 identic 63\n",
      "64 identic 64\n",
      "65 identic 65\n",
      "66 identic 66\n",
      "67 identic 67\n",
      "68 identic 68\n",
      "69 identic 69\n",
      "70 identic 70\n",
      "71 identic 71\n",
      "72 identic 72\n",
      "73 identic 73\n",
      "74 identic 74\n",
      "75 identic 75\n",
      "76 identic 76\n",
      "77 identic 77\n",
      "78 identic 78\n",
      "79 identic 79\n",
      "80 identic 80\n",
      "81 identic 81\n",
      "82 identic 82\n",
      "83 identic 83\n",
      "84 identic 84\n",
      "85 identic 85\n",
      "86 identic 86\n",
      "87 identic 87\n",
      "88 identic 88\n",
      "89 identic 89\n",
      "90 identic 90\n",
      "91 identic 91\n",
      "92 identic 92\n",
      "93 identic 93\n",
      "94 identic 94\n",
      "95 identic 95\n",
      "96 identic 96\n",
      "97 identic 97\n",
      "98 identic 98\n"
     ]
    }
   ],
   "source": [
    "## HW*\n",
    "# 1. download more than 1500+\n",
    "# 2. wrap the code bellow in one more loop \n",
    "# 3. remove either manually,  or using os.remove()\n",
    "\n",
    "## detect wich images are identic with a selected one \n",
    "for n in range(0,99):\n",
    "    number1 = n\n",
    "    file_name = f\"image_{number1:05d}.jpg\"\n",
    "    file1 = open(\"images/sharpened\"+\"/\"+file_name, \"rb\")\n",
    "    content_1 = file1.read() \n",
    "    file1.close()\n",
    "\n",
    "    for number in range(0,99):\n",
    "        \n",
    "        file_name = f\"image_{number:05d}.jpg\"\n",
    "        file1 = open(\"images/sharpened\"+\"/\"+file_name, \"rb\")\n",
    "        content = file1.read() \n",
    "        file1.close()\n",
    "\n",
    "        if content_1 == content:\n",
    "            print(f\"{number1} identic {number}\")\n",
    "\n",
    "      \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ML_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fa1869d48508ae027acca88019d77fb35d0ae569849f7efe365cc6f3fee5449"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
