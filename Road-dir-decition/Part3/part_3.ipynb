{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear NN / CLASIFICATION / DECISION MAKING\n",
    "# PART 3\n",
    "## LET'S solve the same problem using NN of Multiple NEURONS \n",
    "\n",
    "### The DNN will be composed of 3 layers:\n",
    "* input  layer\n",
    "* hiden  layer\n",
    "* output layer\n",
    "#### A simple NN wold look like this\n",
    ">  the direction of arrow is the FORWARD pass\n",
    "\n",
    "<img src=\"img5.png\" style=\"width:500px;height 500px\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "### A more complex DNN wold look like this\n",
    "> the direction of the arrow is the FORWARD pass\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"img6.png\" style=\"width:500px;height 500px\"/>\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we take layer separatlly\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"img7.png\" style=\"width:500px;height 500px\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Each layer can be aproximated like this\n",
    "<br>\n",
    "\n",
    "<img src=\"img8.png\" style=\"width:500px;height 500px\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### We can transpose  the drawing so it becomes clearer\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"img9.png\" style=\"width:500px;height 500px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "class  LinearLayer:\n",
    "    \n",
    "    def __init__ (self, x_size, y_size):\n",
    "        \n",
    "        # layer size\n",
    "        self.x_size = x_size\n",
    "        self.y_size = y_size\n",
    "\n",
    "        # input layer\n",
    "        self.x = [ 0 for i in range(x_size) ]\n",
    "\n",
    "        # paramaters\n",
    "        self.b = [ random() for j in range(y_size) ] \n",
    "        self.w = [\n",
    "            [ random() for i in range(x_size)] for j in range(y_size)\n",
    "        ]\n",
    "       \n",
    "        # output layer\n",
    "        self.y = [ 0 for j in range(y_size) ]\n",
    "\n",
    "    def forward(self,x):\n",
    "        # guarding input vector dimension\n",
    "        if len(x) != self.x_size:\n",
    "            print(f'EROR: input size must be{self.x_size} but {len(x)} given')\n",
    "            return\n",
    "\n",
    "        # memorizing input values\n",
    "        self.x = x\n",
    "        \n",
    " \n",
    "        # computing forward pass\n",
    "        for j in range(self.y_size):\n",
    "            self.y[j] = sum([ self.w[j][i] * self.x[i] for i in range(self.x_size)] ) + self.b[j]\n",
    "    \n",
    "        return self.y\n",
    "\n",
    "    \n",
    "    \n",
    "    def backward(self,delta,lr):\n",
    "        # UPDATE PARAMS\n",
    "        # dW = dE * x\n",
    "        w_delta = [\n",
    "            [delta[j]* self.x[i] for i in range(self.x_size) ] for j in range(len(delta))\n",
    "        ]\n",
    "        # w -= dW \n",
    "        self.w = [\n",
    "            [self.w[j][i] -lr * w_delta [j][i] for i in range(self.x_size)] for j in range(len(w_delta))\n",
    "        ]\n",
    "        self.b = [ self.b[j]- lr * delta[j] for j in range(len(delta)) ]\n",
    "\n",
    "        # BACK PASS THE ERROR\n",
    "        x_delta = [\n",
    "            sum([delta[j]* self.w[j][i] for j in range(len(delta))]) for i in range(self.x_size)\n",
    "        ]\n",
    "        return x_delta\n",
    "\n",
    "    \n",
    "    def __str__(self):\n",
    "        out = '-'*100+ '\\n'\n",
    "\n",
    "        for i in range(self.x_size):\n",
    "            out += f'{ self.x[i]:17.5f}'\n",
    "        out += '\\n'\n",
    "\n",
    "        for i in range(self.x_size):\n",
    "            out += f'{\"v\":>17}'\n",
    "        out += '\\n\\n'\n",
    "        \n",
    "        for j in range(self.y_size):\n",
    "            for i in range(self.x_size):\n",
    "                out += f'      x{self.w[j][i]:11.5f}' \n",
    "\n",
    "            out += f'     +{self.b[j]:15.5f}'\n",
    "            out += f' > {self.y[j]:15.5f}'\n",
    "            out += '\\n'\n",
    "        out += '-'*100+ '\\n' \n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer:\n",
    "\n",
    "    def __init__(self, x_size):\n",
    "        self.x_size = x_size\n",
    "        self.x = [0 for i in range(x_size)]\n",
    "        self.y = [0 for i in range(x_size)]\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        for i in range(self.x_size):\n",
    "            self.y[i] = self.sigmoid(x[i])\n",
    "        return self.y\n",
    "\n",
    "    def backward(self,delta):\n",
    "        return [delta[i]* self.sigmoid_prime(self.x[i])for i in range(self.x_size)]   \n",
    "\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1/ (1+2.7 ** -x) \n",
    "    \n",
    "    def sigmoid_prime(self,delta):\n",
    "        return self.sigmoid(delta) * (1 - self.sigmoid(delta))\n",
    "\n",
    "    \n",
    "    def __str__(self):\n",
    "        out = '-'*100+ '\\n' \n",
    "\n",
    "        for i in range(self.x_size):\n",
    "            out += f'{ self.x[i]:17.5f}'\n",
    "        out += '\\n'\n",
    "\n",
    "        for i in range(self.x_size):\n",
    "            out += f'{\"v\":>17}'\n",
    "        out += '\\n\\n'\n",
    "\n",
    "        for i in range(self.x_size):\n",
    "            out += f'{ self.y[i]:17.5f}'\n",
    "        out += '\\n'\n",
    "\n",
    "        out += '-'*100+ '\\n' \n",
    "        \n",
    "        return out\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Activation Layer\n",
    "* non-lineary(triggering)\n",
    "* output normalization\n",
    "* sensibility focus<br><br>\n",
    "<img src=\"img10.png\" style=\"width:300px;height 300px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "          1.00000          1.00000\n",
      "                v                v\n",
      "\n",
      "      x    1.00000      x    1.00000     +        1.00000 >         3.00000\n",
      "      x    0.28102      x    0.83592     +        0.70643 >         1.82337\n",
      "      x    1.00000      x    0.97693     +        0.68690 >         2.66384\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[3, 1.8233748060145354, 2.6638396931774273]\n"
     ]
    }
   ],
   "source": [
    "hiden_layer = LinearLayer(2,3)\n",
    "\n",
    "hiden_layer.b[0] = 1\n",
    "hiden_layer.w[0][0] = 1\n",
    "hiden_layer.w[0][1] = 1\n",
    "\n",
    "hiden_layer.w[2][0] = 1\n",
    "\n",
    "\n",
    "\n",
    "x =[1,1]\n",
    "\n",
    "y = hiden_layer.forward(x)\n",
    "\n",
    "print (hiden_layer)\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's \"stack\" a few layers \n",
    "> and compare the result WITH and WITHOUT the activation layers in between<br>\n",
    "\n",
    "\n",
    "<img src=\"img11.png\" style=\"width:600px;height 400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "          1.00000          0.00000          0.00000\n",
      "                v                v                v\n",
      "\n",
      "      x    3.00000      x    2.00000      x    1.00000     +        0.22456 >         3.22456\n",
      "      x    0.56297      x    0.50271      x    0.41696     +        0.61056 >         1.17353\n",
      "      x    0.41919      x    0.83954      x    0.40188     +        0.44006 >         0.85925\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "          3.22456          1.17353          0.85925\n",
      "                v                v                v\n",
      "\n",
      "          0.96094          0.76235          0.70129\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "          0.96094          0.76235          0.70129\n",
      "                v                v                v\n",
      "\n",
      "      x    3.00000      x    2.00000      x    1.00000     +        0.31174 >         5.42056\n",
      "      x    0.76445      x    0.83247      x    0.05150     +        0.44340 >         1.84873\n",
      "      x    0.29411      x    0.66512      x    0.43223     +        0.89676 >         1.98956\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "          5.42056          1.84873          1.98956\n",
      "                v                v                v\n",
      "\n",
      "          0.99543          0.86251          0.87827\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "          0.99543          0.86251          0.87827\n",
      "                v                v                v\n",
      "\n",
      "      x    3.00000      x    2.00000      x    1.00000     +        0.70246 >         6.29204\n",
      "      x    0.82650      x    0.21892      x    0.38690     +        0.73788 >         2.08923\n",
      "      x    0.03815      x    0.77549      x    0.25380     +        0.82228 >         1.75203\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "          6.29204          2.08923          1.75203\n",
      "                v                v                v\n",
      "\n",
      "          0.99807          0.88846          0.85071\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[0.9980724479055736, 0.8884620944595082, 0.8507132566997537]\n"
     ]
    }
   ],
   "source": [
    "l0 = LinearLayer(3,3)\n",
    "a0 = ActivationLayer(3)\n",
    "l0.w[0][0] = 3\n",
    "l0.w[0][1] = 2\n",
    "l0.w[0][2] = 1\n",
    "\n",
    "l1 = LinearLayer(3,3)\n",
    "a1 = ActivationLayer(3)\n",
    "l1.w[0][0] = 3\n",
    "l1.w[0][1] = 2\n",
    "l1.w[0][2] = 1\n",
    "\n",
    "l2 = LinearLayer(3,3)\n",
    "a2 = ActivationLayer(3)\n",
    "l2.w[0][0] = 3\n",
    "l2.w[0][1] = 2\n",
    "l2.w[0][2] = 1\n",
    "\n",
    "x = [1,0,0]\n",
    "\n",
    "# forward\n",
    "# HW1 : draw a diagram\n",
    "y0 = l0.forward(x)\n",
    "ya0 = a0.forward(y0)\n",
    "y1 = l1.forward(ya0)\n",
    "ya1 = a1.forward(y1)\n",
    "y2 = l2.forward(ya1)\n",
    "ya2 = a2.forward(y2)\n",
    "\n",
    "y = ya2\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(l0)\n",
    "print(a0)\n",
    "print(l1)\n",
    "print(a1)\n",
    "print(l2)\n",
    "print(a2)\n",
    "\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's assemble our network (this time without a HIDDEN LAYER)<br><br>\n",
    "<img src=\"img12.png\" style=\"width:800px;height 800px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square error\n",
    "def mse(y, yp):\n",
    "    return sum( [ (y[j] - yp[j]) ** 2 for j in range(len(y))] ) / len(y)\n",
    "# mse delta |\n",
    "#           v\n",
    "def mse_prime(y, yp):\n",
    "    return [2 * (yp[j] - y [j]) / len(y) for j in range(len(y))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lo.w[0][0] = 3\n",
    "# lo.w[0][1] = 2\n",
    "# lo.w[0][2] = 1\n",
    "\n",
    "\n",
    "# x = [0,1]\n",
    "\n",
    "# forward\n",
    "\n",
    "# yi = li.forward(x)\n",
    "# yai = ai.forward(yi)\n",
    "# yo = lo.forward(yai)\n",
    "# yao = ao.forward(yo)\n",
    "\n",
    "# y = yao\n",
    "\n",
    "# print(x)\n",
    "\n",
    "# print(li)\n",
    "# print(ai)\n",
    "# print(lo)\n",
    "# print(ao)\n",
    "\n",
    "\n",
    "\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does BACKPROPAGATION work?\n",
    "<img src=\"img14.png\" style=\"width:300px;height 300px\"/> <br>\n",
    "<img src=\"img15.png\" style=\"width:800px;height 800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation in more details\n",
    "parameter update (delta) depends on the input\n",
    "\n",
    "\n",
    "<img src=\"img16.png\" style=\"width:300px;height 300px\"/> <br>\n",
    "\n",
    "Error back propagation\n",
    "\n",
    "<img src=\"img17.png\" style=\"width:300px;height 300px\"/>\n",
    "<img src=\"img18.png\" style=\"width:300px;height 300px\"/> <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = LinearLayer(2,3)\n",
    "ai = ActivationLayer(3)\n",
    "\n",
    "lo = LinearLayer(3,1)\n",
    "ao = ActivationLayer(1)\n",
    "\n",
    "\n",
    "x_train = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "\n",
    "]\n",
    "\n",
    "y_train = [\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "]\n",
    "\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "\n",
    "for epoch in range(100000):\n",
    "    \n",
    "    yp = []\n",
    "    for i in range(len(x_train)):\n",
    "        # predict\n",
    "        yi  = li.forward(x_train[i])\n",
    "        yai = ai.forward(yi)\n",
    "        yo  = lo.forward(yai)\n",
    "        y   = ao.forward(yo)\n",
    "        \n",
    "        yp.append(y[0])\n",
    "    # print(yp)    \n",
    "\n",
    "    #loss\n",
    "   \n",
    "\n",
    "    # Back Propagation\n",
    "        delta = mse_prime([y_train[i]], y)\n",
    "        delta = ao.backward(delta)\n",
    "        delta = lo.backward(delta,lr)\n",
    "        delta = ai.backward(delta)\n",
    "        delta = li.backward(delta,lr)\n",
    "\n",
    "    error = mse(y_train, yp)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"{epoch: 10}, error = {error:10.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] [0.006757273504589349] [0, 1, 1, 0]\n",
      "[0, 1] [0.9960039355819899] [0, 1, 1, 0]\n",
      "[1, 0] [0.9902157180007475] [0, 1, 1, 0]\n",
      "[1, 1] [0.00829048412118025] [0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_train)):\n",
    "    # predict\n",
    "    yi  = li.forward(x_train[i])\n",
    "    yai = ai.forward(yi)\n",
    "    yo  = lo.forward(yai)\n",
    "    y   = ao.forward(yo)\n",
    "\n",
    "    print(x_train[i], y, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
